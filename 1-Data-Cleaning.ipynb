{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem statement\n",
    "\n",
    "This project is meant as an exercise in basic classification as a training after reading the first three chapters of Hands-On Machine Learning with Scikit-Learn, Keras and Tensorflow by GÃ©ron.\n",
    "\n",
    "### Learning goal: practise implementing a simple end-to-end classification task\n",
    "Rather than try and achieve very performant results (e.g. optimising an accuracy metric) a focus is to cover all major steps of a typical classification task:\n",
    "1. Data collection\n",
    "2. Data cleaning and preprocessing\n",
    "3. Exploratory data analysis\n",
    "4. Training of Machine Learning algorithms\n",
    "5. Optimising the chosen ML technique\n",
    "6. Drawing insights and conclusions\n",
    "7. Deployment\n",
    "\n",
    "The sequential steps are described in separate notebooks.\n",
    "\n",
    "### Business goal: detect customers that are likely to cancel their credit-card subscription\n",
    "I found the dataset on Kaggle:\n",
    "https://www.kaggle.com/sakshigoyal7/credit-card-customers\n",
    "\n",
    "It comes from a real-life scenario: a bank manager is unhappy that quite a few customers have been cancelling their credit card membership. He/She wants to find out if it's possible to detect such discontent customers early on and win them over by proposing attractive offers before it's too late.\n",
    "The data has been collected by a Kaggle user, however, it requires some preparation due to:\n",
    "- text rather than numeric values\n",
    "- missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load utilities and programming set up\n",
    "\n",
    "Let's start by loading the useful libraries, specifying the input data file, and preparing a utility function that will be used to save any figures later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usual imports\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# Pretty plotting\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Data file name (easy to change for a similar project)\n",
    "DATA_FILE = \"BankChurners.csv\"\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\")\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)  # It's fine if the directory already exists (No action needed)\n",
    "\n",
    "def save_fig(fig_name, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    \"Save figure ensurring correct directory, extension, resolution and layout\"\n",
    "    path = os.path.join(IMAGES_PATH, fig_name + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_name)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
    "\n",
    "# Ignore useless warnings (see SciPy issue #5998)\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and have a glimpse at the data\n",
    "\n",
    "Below I define and call a utility function that loads the data into a pandas DataFrame.\n",
    "Then, we can have a glimpse at the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        3\n",
       "1        2\n",
       "2        0\n",
       "3        1\n",
       "4        0\n",
       "        ..\n",
       "10122    3\n",
       "10123    3\n",
       "10124    4\n",
       "10125    3\n",
       "10126    4\n",
       "Name: Contacts_Count_12_mon, Length: 10127, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_data(data_path = PROJECT_ROOT_DIR, data_file = DATA_FILE):\n",
    "    \"Load csv data into a pandas DataFrame\"\n",
    "    csv_path = os.path.join(data_path, data_file)\n",
    "    return pd.read_csv(csv_path)\n",
    "df = load_data()\n",
    "df.head(100)\n",
    "df[\"Contacts_Count_12_mon\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we see that most of the columns are numerical (`int64` or `float64`), while a few are text-based (`object`).\n",
    "Let's inspect possible values of the latter ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10127 entries, 0 to 10126\n",
      "Data columns (total 23 columns):\n",
      " #   Column                                                                                                                              Non-Null Count  Dtype  \n",
      "---  ------                                                                                                                              --------------  -----  \n",
      " 0   CLIENTNUM                                                                                                                           10127 non-null  int64  \n",
      " 1   Attrition_Flag                                                                                                                      10127 non-null  object \n",
      " 2   Customer_Age                                                                                                                        10127 non-null  int64  \n",
      " 3   Gender                                                                                                                              10127 non-null  object \n",
      " 4   Dependent_count                                                                                                                     10127 non-null  int64  \n",
      " 5   Education_Level                                                                                                                     10127 non-null  object \n",
      " 6   Marital_Status                                                                                                                      10127 non-null  object \n",
      " 7   Income_Category                                                                                                                     10127 non-null  object \n",
      " 8   Card_Category                                                                                                                       10127 non-null  object \n",
      " 9   Months_on_book                                                                                                                      10127 non-null  int64  \n",
      " 10  Total_Relationship_Count                                                                                                            10127 non-null  int64  \n",
      " 11  Months_Inactive_12_mon                                                                                                              10127 non-null  int64  \n",
      " 12  Contacts_Count_12_mon                                                                                                               10127 non-null  int64  \n",
      " 13  Credit_Limit                                                                                                                        10127 non-null  float64\n",
      " 14  Total_Revolving_Bal                                                                                                                 10127 non-null  int64  \n",
      " 15  Avg_Open_To_Buy                                                                                                                     10127 non-null  float64\n",
      " 16  Total_Amt_Chng_Q4_Q1                                                                                                                10127 non-null  float64\n",
      " 17  Total_Trans_Amt                                                                                                                     10127 non-null  int64  \n",
      " 18  Total_Trans_Ct                                                                                                                      10127 non-null  int64  \n",
      " 19  Total_Ct_Chng_Q4_Q1                                                                                                                 10127 non-null  float64\n",
      " 20  Avg_Utilization_Ratio                                                                                                               10127 non-null  float64\n",
      " 21  Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1  10127 non-null  float64\n",
      " 22  Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2  10127 non-null  float64\n",
      "dtypes: float64(7), int64(10), object(6)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "Attrition_Flag\n",
      "==============================\n",
      "Existing Customer    8500\n",
      "Attrited Customer    1627\n",
      "Name: Attrition_Flag, dtype: int64\n",
      "==============================\n",
      "Gender\n",
      "==============================\n",
      "F    5358\n",
      "M    4769\n",
      "Name: Gender, dtype: int64\n",
      "==============================\n",
      "Education_Level\n",
      "==============================\n",
      "Graduate         3128\n",
      "High School      2013\n",
      "Unknown          1519\n",
      "Uneducated       1487\n",
      "College          1013\n",
      "Post-Graduate     516\n",
      "Doctorate         451\n",
      "Name: Education_Level, dtype: int64\n",
      "==============================\n",
      "Marital_Status\n",
      "==============================\n",
      "Married     4687\n",
      "Single      3943\n",
      "Unknown      749\n",
      "Divorced     748\n",
      "Name: Marital_Status, dtype: int64\n",
      "==============================\n",
      "Income_Category\n",
      "==============================\n",
      "Less than $40K    3561\n",
      "$40K - $60K       1790\n",
      "$80K - $120K      1535\n",
      "$60K - $80K       1402\n",
      "Unknown           1112\n",
      "$120K +            727\n",
      "Name: Income_Category, dtype: int64\n",
      "==============================\n",
      "Card_Category\n",
      "==============================\n",
      "Blue        9436\n",
      "Silver       555\n",
      "Gold         116\n",
      "Platinum      20\n",
      "Name: Card_Category, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df.select_dtypes(np.object).head()\n",
    "text_cols = df.select_dtypes(np.object).columns\n",
    "text_cols\n",
    "for col in text_cols:\n",
    "    print(30*'=')\n",
    "    print(col)\n",
    "    print(30*'=')\n",
    "    print(df[col].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "We spot that there are 'Unknown' values in the columns: 'Education_Level', 'Marital_Status' and 'Income_Category'.\n",
    "They are actually NaN's and let's mark them as such explicitely with `df.replace(.)` and `np.nan`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Married     4687\n",
      "Single      3943\n",
      "Divorced     748\n",
      "Name: Marital_Status, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CLIENTNUM                                                                                                                                0\n",
       "Attrition_Flag                                                                                                                           0\n",
       "Customer_Age                                                                                                                             0\n",
       "Gender                                                                                                                                   0\n",
       "Dependent_count                                                                                                                          0\n",
       "Education_Level                                                                                                                       1519\n",
       "Marital_Status                                                                                                                         749\n",
       "Income_Category                                                                                                                       1112\n",
       "Card_Category                                                                                                                            0\n",
       "Months_on_book                                                                                                                           0\n",
       "Total_Relationship_Count                                                                                                                 0\n",
       "Months_Inactive_12_mon                                                                                                                   0\n",
       "Contacts_Count_12_mon                                                                                                                    0\n",
       "Credit_Limit                                                                                                                             0\n",
       "Total_Revolving_Bal                                                                                                                      0\n",
       "Avg_Open_To_Buy                                                                                                                          0\n",
       "Total_Amt_Chng_Q4_Q1                                                                                                                     0\n",
       "Total_Trans_Amt                                                                                                                          0\n",
       "Total_Trans_Ct                                                                                                                           0\n",
       "Total_Ct_Chng_Q4_Q1                                                                                                                      0\n",
       "Avg_Utilization_Ratio                                                                                                                    0\n",
       "Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1       0\n",
       "Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.replace(\"Unknown\", np.nan)\n",
    "print(df[\"Marital_Status\"].value_counts())\n",
    "df[\"Income_Category\"].value_counts()\n",
    "\n",
    "# df.isnull().sum() > 0\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Existing Customer    83.934038\n",
       "Attrited Customer    16.065962\n",
       "Name: Attrition_Flag, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show percentage of attrited and existing customers\n",
    "df[\"Attrition_Flag\"].value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that:\n",
    "- The first column is a unique client number; we won't need it\n",
    "- The second one is the client category: either \"Existing Customer\" or \"Attrited Customer\". We'll use it as a label for the classification algorithms. Note the imbalance between the existing (84%) and attrited (16%) customers. Hence the problem we're dealing with is actually **imbalanced classification** (more on it below)\n",
    "- The next columns are various characteristics of each customer, potentially feautures of an ML algorithm\n",
    "- Some columns are text-based. They need to be translated into numeric values to be ready for an ML technique.\n",
    "\n",
    "### Imbalanced classification\n",
    "Having the class ratio significantly different from 1:1 (as it is the case here) may cause an ML algorithm to ignore the minority class. This is obviously undesirable.\n",
    "While there's no magic solution to the problem, there exist a number of strategies to try out:\n",
    "1. Use a more suitable performance metric than accuracy, e.g. confusion matrix\n",
    "2. Over(under) sample the minority (majority) class.\n",
    "3. Syntehise the feautures of the minory class to manufacture plausible new instances of the minority class (the SMOTE technique)\n",
    "3. Choose an algorithm that can mitigate the imbalanced class representation\n",
    "4. Gather more data (not feasible if the imbalance is intrinsic to the process as it is the case in churn/anomaly/fraud detection, etc.)\n",
    "\n",
    "More information:\n",
    "- https://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/\n",
    "- SMOTE: https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/\n",
    "\n",
    "For the step-by-step development I'd proceed as follows:\n",
    "1. Ignore the \"elephant in the room\" to firstly focus on the overall workflow\n",
    "2. Use the confusion matrix (or similar) as a peformance measure\n",
    "3. Pick an easy solution to tackle the imbalanced classification (e.g. over-sample the minority class)\n",
    "\n",
    "### Remove obviously-not-needed columns\n",
    "The dataset author tells that he's been working on Naive Bayes classifier with no satisfactory outcome.\n",
    "Therefore the corresponding columns are rather *outputs* than *inputs* (features) and let's drop them together with the client number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1\n",
      "Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2\n",
      "CLIENTNUM\n"
     ]
    }
   ],
   "source": [
    "for col in [\n",
    "    \"Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1\",\n",
    "    \"Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2\",\n",
    "    \"CLIENTNUM\",\n",
    "    ]:\n",
    "    print(col)\n",
    "    df = df.drop(col, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translate text to numbers \n",
    "\n",
    "### How to transform the text values?\n",
    "- \"Income_Category\" is actually a numerical column, except it needs a transformation (e.g. assigning mean of the range)\n",
    "- \"Education_Level\" and \"Card_Category\" represent some progression, except the former is unsorted\n",
    "  - We'll sort the former by a dedicated function and assign a numerical value\n",
    "  - We'll use an ordinal encoder for the latter\n",
    "- \"Marital_Status\" doesn't exhibit a progression, but rather \"one of many types\" pattern; it may be tackled with one-hot encoder\n",
    "- \"Gender\" would also suit to one-hot encoder (or perhaps an ordinal encoder, since there are 2 values only?)\n",
    "\n",
    "\n",
    "### How to deal with unknown values?\n",
    "- The (tranformed into) numerical values may be assigned the mean\n",
    "- The 'unknown' marital status or gender is more challenging; we can e.g.\n",
    "  - skip these features altogether, not to bias the algorithm\n",
    "  - assign a random value according to the feature distribution\n",
    "  - assign their most frequent values\n",
    "  - skip the instances (i.e. customers) who didn't provide either of these\n",
    "- To simplify let's skip the marital status and gender altogether\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_edu(val):\n",
    "    \"Sort education level correctly\"\n",
    "    order = [\"Uneducated\", \"High School\", \"College\", \"Graduate\", \"Post-Graduate\", \"Doctorate\"]\n",
    "    if val in order:\n",
    "        return order.index(val)\n",
    "    # For unknowns return NaN to later on apply median\n",
    "    return np.nan\n",
    "\n",
    "#df['Education'] = df.apply(lambda x: sort_edu(x[\"Education_Level\"]), axis=1)\n",
    "df['Education_Level'] = df['Education_Level'].map(sort_edu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         70.0\n",
       "1         40.0\n",
       "2        100.0\n",
       "3         40.0\n",
       "4         70.0\n",
       "         ...  \n",
       "10122     50.0\n",
       "10123     50.0\n",
       "10124     40.0\n",
       "10125     50.0\n",
       "10126     40.0\n",
       "Name: Income_Category, Length: 10127, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def avg_income(val):\n",
    "    'Replace income ranges with range averages using regexps, eg. \"$60K - $80K\" -> 70'\n",
    "    if val is np.nan:\n",
    "        return np.nan\n",
    "    if val == 'Unknown':\n",
    "        return np.nan\n",
    "    import re\n",
    "    matches = re.findall(\"\\$[0-9]*K\", val)\n",
    "    matches = [float(x.replace('$','').replace('K','')) for x in matches]\n",
    "    if len(matches) == 1:\n",
    "        return matches[0]\n",
    "    return sum(matches) / len(matches)\n",
    "#avg_income(\"$60K - $80K\")\n",
    "#df['Avg_Income'] = df.apply(lambda x: avg_income(x['Income_Category']), axis=1)\n",
    "df['Income_Category'] = df['Income_Category'].map(avg_income)\n",
    "df['Income_Category']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build transformation pipeline: encode text-based values and standardisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of positive class: 0.8393403772094401\n",
      "Meaning of 0-class and 1-class: ['Attrited Customer' 'Existing Customer']\n",
      "Num cols: Index(['Customer_Age', 'Dependent_count', 'Education_Level', 'Income_Category',\n",
      "       'Months_on_book', 'Total_Relationship_Count', 'Months_Inactive_12_mon',\n",
      "       'Contacts_Count_12_mon', 'Credit_Limit', 'Total_Revolving_Bal',\n",
      "       'Avg_Open_To_Buy', 'Total_Amt_Chng_Q4_Q1', 'Total_Trans_Amt',\n",
      "       'Total_Trans_Ct', 'Total_Ct_Chng_Q4_Q1', 'Avg_Utilization_Ratio'],\n",
      "      dtype='object')\n",
      "Ordinal cols: ['Card_Category']\n"
     ]
    }
   ],
   "source": [
    "# Load sklearn transformation tools\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Numerical pipeline\n",
    "num_cols_names = df.select_dtypes(exclude=np.object).columns\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "    ('std_scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Ordinal categories' pipeline\n",
    "ordinal_cols_names = [\"Card_Category\"]\n",
    "\n",
    "# Full pipeline\n",
    "# ColumnTransformer executes the pipelines on specified lists of column names\n",
    "full_pipeline = ColumnTransformer([\n",
    "    ('num', num_pipeline, num_cols_names),\n",
    "    ('ordered', OrdinalEncoder(), ordinal_cols_names)\n",
    "    #('cat', OneHotEncoder(), text_cols_names),\n",
    "])\n",
    "\n",
    "# Split feature matrix and the label vector\n",
    "X = df.drop(\"Attrition_Flag\", axis=1)\n",
    "y = df['Attrition_Flag'].copy()\n",
    "\n",
    "# Transform the feauture matrix with the pipeline\n",
    "X_tr = full_pipeline.fit_transform(X)\n",
    "\n",
    "# Transform the label vector using the LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_tr = le.fit_transform(y)\n",
    "print(\"Percentage of positive class:\", y_tr.sum()/y_tr.shape[0])\n",
    "print(\"Meaning of 0-class and 1-class:\", le.inverse_transform([0,1]))\n",
    "print(\"Num cols:\", num_cols_names)\n",
    "print(\"Ordinal cols:\", ordinal_cols_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the next paragraphs, the notions of true/false postive/negative will be used.\n",
    "The `LabelEncoder` classified active clients as _positive_ and the churned ones as _negatives_.\n",
    "Actually, it would be more convenient to define them the other way round: a churning client should be the positive outcome of the model (similar to detecting any rare signal, e.g. disease, fraud, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1606596227905599"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tr = np.where(y_tr==0, 1, 0) # swap 0 and 1\n",
    "y_tr.sum() / y_tr.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train and test sets\n",
    "Despite we're only at the cleaning stage, it's a good practice to already seperate out the test set from the training one to avoid (analyst's) biases.\n",
    "\n",
    "Let's use 20% of the dataset as the test sample.\n",
    "To ensure representative sampling we're using the stratified shuffle split: the feautures distributions should agree between the train and test samples.\n",
    "However, stratified sampling does not address the above-mentioned _imbalance_ between the class labels.\n",
    "TODO: Let's keep that in mind and tackle at a later stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1607208986544871\n",
      "0.16041461006910168\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "# >>> for train_index, test_index in sss.split(X, y):\n",
    "# ...     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "# ...     X_train, X_test = X[train_index], X[test_index]\n",
    "# ...     y_train, y_test = y[train_index], y[test_index]\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(X_tr, y_tr):\n",
    "    X_train, X_test = X_tr[train_index], X_tr[test_index]\n",
    "    y_train, y_test = y_tr[train_index], y_tr[test_index]\n",
    "    \n",
    "print(y_train.sum()/y_train.shape[0])\n",
    "print(y_test.sum()/y_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the dataset for the next step\n",
    "For the sake of clarity, let's save the current dataset using the `pickle` module, before further steps.\n",
    "In the next notebook we'll explore the data and engineer the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Customer_Age',\n",
       " 'Dependent_count',\n",
       " 'Education_Level',\n",
       " 'Income_Category',\n",
       " 'Months_on_book',\n",
       " 'Total_Relationship_Count',\n",
       " 'Months_Inactive_12_mon',\n",
       " 'Contacts_Count_12_mon',\n",
       " 'Credit_Limit',\n",
       " 'Total_Revolving_Bal',\n",
       " 'Avg_Open_To_Buy',\n",
       " 'Total_Amt_Chng_Q4_Q1',\n",
       " 'Total_Trans_Amt',\n",
       " 'Total_Trans_Ct',\n",
       " 'Total_Ct_Chng_Q4_Q1',\n",
       " 'Avg_Utilization_Ratio',\n",
       " 'Card_Category']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape\n",
    "#len(num_cols_names)\n",
    "list(list(num_cols_names)+list(ordinal_cols_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer_Age</th>\n",
       "      <th>Dependent_count</th>\n",
       "      <th>Education_Level</th>\n",
       "      <th>Income_Category</th>\n",
       "      <th>Months_on_book</th>\n",
       "      <th>Total_Relationship_Count</th>\n",
       "      <th>Months_Inactive_12_mon</th>\n",
       "      <th>Contacts_Count_12_mon</th>\n",
       "      <th>Credit_Limit</th>\n",
       "      <th>Total_Revolving_Bal</th>\n",
       "      <th>Avg_Open_To_Buy</th>\n",
       "      <th>Total_Amt_Chng_Q4_Q1</th>\n",
       "      <th>Total_Trans_Amt</th>\n",
       "      <th>Total_Trans_Ct</th>\n",
       "      <th>Total_Ct_Chng_Q4_Q1</th>\n",
       "      <th>Avg_Utilization_Ratio</th>\n",
       "      <th>Card_Category</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.288101</td>\n",
       "      <td>-1.806378</td>\n",
       "      <td>-0.039873</td>\n",
       "      <td>-0.837746</td>\n",
       "      <td>-1.493661</td>\n",
       "      <td>0.120579</td>\n",
       "      <td>0.651940</td>\n",
       "      <td>-0.411616</td>\n",
       "      <td>-0.667004</td>\n",
       "      <td>1.309516</td>\n",
       "      <td>-0.784263</td>\n",
       "      <td>-0.337327</td>\n",
       "      <td>-0.779840</td>\n",
       "      <td>-0.973895</td>\n",
       "      <td>-1.109831</td>\n",
       "      <td>2.151448</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.290150</td>\n",
       "      <td>0.503368</td>\n",
       "      <td>-0.807534</td>\n",
       "      <td>0.312139</td>\n",
       "      <td>0.008965</td>\n",
       "      <td>0.763943</td>\n",
       "      <td>-0.337598</td>\n",
       "      <td>0.492404</td>\n",
       "      <td>1.831365</td>\n",
       "      <td>-1.426858</td>\n",
       "      <td>1.958900</td>\n",
       "      <td>0.406300</td>\n",
       "      <td>-0.624701</td>\n",
       "      <td>-1.144315</td>\n",
       "      <td>-0.542782</td>\n",
       "      <td>-0.997155</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.040662</td>\n",
       "      <td>-0.266547</td>\n",
       "      <td>-0.807534</td>\n",
       "      <td>1.462024</td>\n",
       "      <td>-0.742348</td>\n",
       "      <td>1.407306</td>\n",
       "      <td>0.651940</td>\n",
       "      <td>-1.315636</td>\n",
       "      <td>0.334280</td>\n",
       "      <td>-0.304086</td>\n",
       "      <td>0.361471</td>\n",
       "      <td>0.602472</td>\n",
       "      <td>-0.037412</td>\n",
       "      <td>1.028541</td>\n",
       "      <td>0.595518</td>\n",
       "      <td>-0.714216</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.288101</td>\n",
       "      <td>-0.266547</td>\n",
       "      <td>0.727789</td>\n",
       "      <td>-0.837746</td>\n",
       "      <td>-1.493661</td>\n",
       "      <td>-0.522785</td>\n",
       "      <td>-1.327136</td>\n",
       "      <td>0.492404</td>\n",
       "      <td>-0.606047</td>\n",
       "      <td>0.527870</td>\n",
       "      <td>-0.653244</td>\n",
       "      <td>0.497543</td>\n",
       "      <td>-0.810161</td>\n",
       "      <td>-1.016500</td>\n",
       "      <td>-1.450061</td>\n",
       "      <td>0.852830</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.458314</td>\n",
       "      <td>-1.036462</td>\n",
       "      <td>0.727789</td>\n",
       "      <td>2.228614</td>\n",
       "      <td>0.509840</td>\n",
       "      <td>0.120579</td>\n",
       "      <td>-0.337598</td>\n",
       "      <td>0.492404</td>\n",
       "      <td>2.848054</td>\n",
       "      <td>0.027224</td>\n",
       "      <td>2.845015</td>\n",
       "      <td>-0.159404</td>\n",
       "      <td>-0.156047</td>\n",
       "      <td>0.304255</td>\n",
       "      <td>0.007467</td>\n",
       "      <td>-0.873823</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Customer_Age  Dependent_count  Education_Level  Income_Category  \\\n",
       "0     -1.288101        -1.806378        -0.039873        -0.837746   \n",
       "1     -0.290150         0.503368        -0.807534         0.312139   \n",
       "2     -0.040662        -0.266547        -0.807534         1.462024   \n",
       "3     -1.288101        -0.266547         0.727789        -0.837746   \n",
       "4      0.458314        -1.036462         0.727789         2.228614   \n",
       "\n",
       "   Months_on_book  Total_Relationship_Count  Months_Inactive_12_mon  \\\n",
       "0       -1.493661                  0.120579                0.651940   \n",
       "1        0.008965                  0.763943               -0.337598   \n",
       "2       -0.742348                  1.407306                0.651940   \n",
       "3       -1.493661                 -0.522785               -1.327136   \n",
       "4        0.509840                  0.120579               -0.337598   \n",
       "\n",
       "   Contacts_Count_12_mon  Credit_Limit  Total_Revolving_Bal  Avg_Open_To_Buy  \\\n",
       "0              -0.411616     -0.667004             1.309516        -0.784263   \n",
       "1               0.492404      1.831365            -1.426858         1.958900   \n",
       "2              -1.315636      0.334280            -0.304086         0.361471   \n",
       "3               0.492404     -0.606047             0.527870        -0.653244   \n",
       "4               0.492404      2.848054             0.027224         2.845015   \n",
       "\n",
       "   Total_Amt_Chng_Q4_Q1  Total_Trans_Amt  Total_Trans_Ct  Total_Ct_Chng_Q4_Q1  \\\n",
       "0             -0.337327        -0.779840       -0.973895            -1.109831   \n",
       "1              0.406300        -0.624701       -1.144315            -0.542782   \n",
       "2              0.602472        -0.037412        1.028541             0.595518   \n",
       "3              0.497543        -0.810161       -1.016500            -1.450061   \n",
       "4             -0.159404        -0.156047        0.304255             0.007467   \n",
       "\n",
       "   Avg_Utilization_Ratio  Card_Category  Label  \n",
       "0               2.151448            0.0      0  \n",
       "1              -0.997155            3.0      1  \n",
       "2              -0.714216            0.0      0  \n",
       "3               0.852830            0.0      0  \n",
       "4              -0.873823            0.0      0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save as Pandas DataFrame\n",
    "df_tr = pd.DataFrame(X_train, columns=list(num_cols_names)+ordinal_cols_names)\n",
    "df_tr.head()\n",
    "# Append the labels column\n",
    "df_tr[\"Label\"] = y_train\n",
    "# Write file\n",
    "df_tr.to_pickle(\"Xy_train_df_step1.pickle\")\n",
    "df_tr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write features to file\n",
    "import pickle\n",
    "with open('features.pickle', 'wb') as f:\n",
    "    pickle.dump(list(num_cols_names)+ordinal_cols_names, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"X_train_step1.pickle\", X_train)\n",
    "np.save(\"X_test_step1.pickle\", X_test)\n",
    "np.save(\"y_train_step1.pickle\", y_train)\n",
    "np.save(\"y_test_step1.pickle\", y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
